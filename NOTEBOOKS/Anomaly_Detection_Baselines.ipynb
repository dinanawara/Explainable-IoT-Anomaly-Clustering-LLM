{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05017ae9",
   "metadata": {},
   "source": [
    "# Anomaly Detection Baselines for Bot-IoT\n",
    "\n",
    "Implementing unsupervised anomaly detection models (Isolation Forest, LOF) with proper preprocessing and train/test split to establish baselines for comparison with LLM-based clustering approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51271223",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020b663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANOMALY DETECTION BASELINES - DATA LOADING\n",
      "================================================================================\n",
      "\n",
      "Dataset loaded: 150,477 rows × 46 columns\n",
      "Features: ['pkSeqID', 'stime', 'flgs', 'flgs_number', 'proto', 'proto_number', 'saddr', 'sport', 'daddr', 'dport', 'pkts', 'bytes', 'state', 'state_number', 'ltime', 'seq', 'dur', 'mean', 'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP', 'TnP_PSrcIP', 'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport', 'AR_P_Proto_P_SrcIP', 'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP', 'N_IN_Conn_P_SrcIP', 'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport', 'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP', 'attack', 'category', 'subcategory']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "file_path = \"/Users/nawara/Desktop/LLM-Clustering-Paper/Bot-IoT-Dataset/bot_iot_balanced_subset_300k.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANOMALY DETECTION BASELINES - DATA LOADING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset loaded: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f595f",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split (No Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7784c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN/TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Train set size: 105,333 samples (70.0%)\n",
      "Test set size: 45,144 samples (30.0%)\n",
      "\n",
      "Train label distribution:\n",
      "attack\n",
      "1    104999\n",
      "0       334\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "attack\n",
      "1    45001\n",
      "0      143\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "# Keep labels only for evaluation, not for training\n",
    "X = df.drop(['attack', 'category', 'subcategory', 'pkSeqID'], axis=1)\n",
    "y = df['attack']  # 0=Normal, 1=Attack\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set size: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nTrain label distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest label distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77635a73",
   "metadata": {},
   "source": [
    "## 3. Feature Preprocessing (Fit on Train Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16101922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE PREPROCESSING (FAST)\n",
      "================================================================================\n",
      "\n",
      "Numeric features: 35\n",
      "Categorical features: 7\n",
      "\n",
      ">>> Encoding categorical features (OrdinalEncoder)...\n",
      "    Encoded 7 categorical features\n",
      ">>> Scaling numeric features (StandardScaler)...\n",
      "    Scaled 35 numeric features\n",
      ">>> Combining features...\n",
      "\n",
      "✓ Preprocessing complete!\n",
      "  Train matrix: (105333, 42)\n",
      "  Test matrix:  (45144, 42)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE PREPROCESSING (FAST)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Separate features again just to be clean\n",
    "X_train = X_train.drop(columns=['attack', 'category', 'subcategory'] if 'attack' in X_train.columns else [])\n",
    "X_test = X_test.drop(columns=['attack', 'category', 'subcategory'] if 'attack' in X_test.columns else [])\n",
    "\n",
    "# Identify columns\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# Encode categoricals (FAST with OrdinalEncoder)\n",
    "# ────────────────────────────────────────\n",
    "print(\"\\n>>> Encoding categorical features (OrdinalEncoder)...\")\n",
    "if len(categorical_features) > 0:\n",
    "    encoder = OrdinalEncoder(\n",
    "        handle_unknown='use_encoded_value', \n",
    "        unknown_value=-1,\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    X_train_cat = encoder.fit_transform(X_train[categorical_features])\n",
    "    X_test_cat = encoder.transform(X_test[categorical_features])\n",
    "    print(f\"    Encoded {len(categorical_features)} categorical features\")\n",
    "else:\n",
    "    X_train_cat = np.array([]).reshape(len(X_train), 0)\n",
    "    X_test_cat = np.array([]).reshape(len(X_test), 0)\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# Scale numeric features\n",
    "# ────────────────────────────────────────\n",
    "print(\">>> Scaling numeric features (StandardScaler)...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test_num = scaler.transform(X_test[numeric_features])\n",
    "print(f\"    Scaled {len(numeric_features)} numeric features\")\n",
    "\n",
    "# ────────────────────────────────────────\n",
    "# Combine (FAST with numpy)\n",
    "# ────────────────────────────────────────\n",
    "print(\">>> Combining features...\")\n",
    "X_train_scaled = np.hstack([X_train_num, X_train_cat]) if X_train_cat.shape[1] > 0 else X_train_num\n",
    "X_test_scaled = np.hstack([X_test_num, X_test_cat]) if X_test_cat.shape[1] > 0 else X_test_num\n",
    "\n",
    "print(f\"\\n✓ Preprocessing complete!\")\n",
    "print(f\"  Train matrix: {X_train_scaled.shape}\")\n",
    "print(f\"  Test matrix:  {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2220a",
   "metadata": {},
   "source": [
    "## 4. Isolation Forest - Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ISOLATION FOREST\n",
      "================================================================================\n",
      "\n",
      ">>> Training Isolation Forest on TRAIN...\n",
      "✓ Isolation Forest trained successfully!\n",
      "\n",
      ">>> Scoring on TRAIN and TEST...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ISOLATION FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train on TRAIN only\n",
    "print(\"\\n>>> Training Isolation Forest on TRAIN...\")\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.1,  # Assume 10% anomalies\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso_forest.fit(X_train_scaled)\n",
    "print(\"✓ Isolation Forest trained successfully!\")\n",
    "\n",
    "# Score on both TRAIN and TEST\n",
    "print(\"\\n>>> Scoring on TRAIN and TEST...\")\n",
    "iso_train_scores = iso_forest.score_samples(X_train_scaled)  # Negative = anomaly\n",
    "iso_test_scores = iso_forest.score_samples(X_test_scaled)\n",
    "\n",
    "iso_train_pred = iso_forest.predict(X_train_scaled)  # -1 = anomaly, 1 = normal\n",
    "iso_test_pred = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "# Convert to anomaly scores (higher = more anomalous)\n",
    "iso_train_anomaly_scores = -iso_train_scores  # Invert so higher is more anomalous\n",
    "iso_test_anomaly_scores = -iso_test_scores\n",
    "\n",
    "print(f\"\\nTrain anomaly scores - Min: {iso_train_anomaly_scores.min():.4f}, Max: {iso_train_anomaly_scores.max():.4f}, Mean: {iso_train_anomaly_scores.mean():.4f}\")\n",
    "print(f\"Test anomaly scores - Min: {iso_test_anomaly_scores.min():.4f}, Max: {iso_test_anomaly_scores.max():.4f}, Mean: {iso_test_anomaly_scores.mean():.4f}\")\n",
    "print(f\"\\nTrain - Detected anomalies: {(iso_train_pred == -1).sum():,} / {len(iso_train_pred):,}\")\n",
    "print(f\"Test - Detected anomalies: {(iso_test_pred == -1).sum():,} / {len(iso_test_pred):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0316af3",
   "metadata": {},
   "source": [
    "## 5. Local Outlier Factor (LOF) - Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698acc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOCAL OUTLIER FACTOR (LOF)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train on TRAIN only\n",
    "print(\"\\n>>> Training LOF on TRAIN...\")\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.1,  # Assume 10% anomalies\n",
    "    novelty=True,  # Enable scoring on new data\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lof.fit(X_train_scaled)\n",
    "print(\"✓ LOF trained successfully!\")\n",
    "\n",
    "# Score on both TRAIN and TEST\n",
    "print(\"\\n>>> Scoring on TRAIN and TEST...\")\n",
    "lof_train_scores = lof.score_samples(X_train_scaled)  # Negative = anomaly\n",
    "lof_test_scores = lof.score_samples(X_test_scaled)\n",
    "\n",
    "lof_train_pred = lof.predict(X_train_scaled)  # -1 = anomaly, 1 = normal\n",
    "lof_test_pred = lof.predict(X_test_scaled)\n",
    "\n",
    "# Convert to anomaly scores (higher = more anomalous)\n",
    "lof_train_anomaly_scores = -lof_train_scores  # Invert so higher is more anomalous\n",
    "lof_test_anomaly_scores = -lof_test_scores\n",
    "\n",
    "print(f\"\\nTrain anomaly scores - Min: {lof_train_anomaly_scores.min():.4f}, Max: {lof_train_anomaly_scores.max():.4f}, Mean: {lof_train_anomaly_scores.mean():.4f}\")\n",
    "print(f\"Test anomaly scores - Min: {lof_test_anomaly_scores.min():.4f}, Max: {lof_test_anomaly_scores.max():.4f}, Mean: {lof_test_anomaly_scores.mean():.4f}\")\n",
    "print(f\"\\nTrain - Detected anomalies: {(lof_train_pred == -1).sum():,} / {len(lof_train_pred):,}\")\n",
    "print(f\"Test - Detected anomalies: {(lof_test_pred == -1).sum():,} / {len(lof_test_pred):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce27990",
   "metadata": {},
   "source": [
    "## 6. Evaluation on Test Set (Using Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17633ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION ON TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert sklearn predictions to binary (0=normal, 1=anomaly)\n",
    "# sklearn: -1 = anomaly, 1 = normal\n",
    "iso_test_binary = (iso_test_pred == -1).astype(int)\n",
    "lof_test_binary = (lof_test_pred == -1).astype(int)\n",
    "y_test_binary = y_test.values  # 0=Normal, 1=Attack\n",
    "\n",
    "def evaluate_model(y_true, y_pred, anomaly_scores, model_name):\n",
    "    \"\"\"Evaluate anomaly detection model\"\"\"\n",
    "    print(f\"\\n>>> {model_name}\")\n",
    "    print(f\"{'─'*60}\")\n",
    "    \n",
    "    # Binary classification metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # ROC-AUC using anomaly scores\n",
    "    roc_auc = roc_auc_score(y_true, anomaly_scores)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  True Negatives:  {tn:,}\")\n",
    "    print(f\"  False Positives: {fp:,}\")\n",
    "    print(f\"  False Negatives: {fn:,}\")\n",
    "    print(f\"  True Positives:  {tp:,}\")\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'TN': tn,\n",
    "        'FN': fn\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "iso_results = evaluate_model(y_test_binary, iso_test_binary, iso_test_anomaly_scores, \"Isolation Forest\")\n",
    "lof_results = evaluate_model(y_test_binary, lof_test_binary, lof_test_anomaly_scores, \"Local Outlier Factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2632cb",
   "metadata": {},
   "source": [
    "## 7. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e39485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Metrics Comparison\n",
    "metrics_df = pd.DataFrame([iso_results, lof_results])\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "x_pos = np.arange(len(metrics_to_plot))\n",
    "width = 0.35\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.bar(x_pos - width/2, metrics_df.loc[0, metrics_to_plot], width, label='Isolation Forest', alpha=0.8, color='steelblue')\n",
    "ax.bar(x_pos + width/2, metrics_df.loc[1, metrics_to_plot], width, label='LOF', alpha=0.8, color='coral')\n",
    "ax.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(metrics_to_plot, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# 2. ROC Curves\n",
    "ax = axes[0, 1]\n",
    "fpr_iso, tpr_iso, _ = roc_curve(y_test_binary, iso_test_anomaly_scores)\n",
    "fpr_lof, tpr_lof, _ = roc_curve(y_test_binary, lof_test_anomaly_scores)\n",
    "\n",
    "ax.plot(fpr_iso, tpr_iso, label=f'Isolation Forest (AUC={iso_results[\"ROC-AUC\"]:.3f})', linewidth=2, color='steelblue')\n",
    "ax.plot(fpr_lof, tpr_lof, label=f'LOF (AUC={lof_results[\"ROC-AUC\"]:.3f})', linewidth=2, color='coral')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=11, fontweight='bold')\n",
    "ax.set_title('ROC Curves', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 3. Anomaly Score Distributions\n",
    "ax = axes[1, 0]\n",
    "ax.hist(iso_test_anomaly_scores[y_test_binary == 0], bins=50, alpha=0.6, label='Normal', color='green')\n",
    "ax.hist(iso_test_anomaly_scores[y_test_binary == 1], bins=50, alpha=0.6, label='Attack', color='red')\n",
    "ax.set_xlabel('Anomaly Score', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Isolation Forest - Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Confusion Matrix Heatmap (Isolation Forest)\n",
    "ax = axes[1, 1]\n",
    "cm_iso = confusion_matrix(y_test_binary, iso_test_binary)\n",
    "sns.heatmap(cm_iso, annot=True, fmt='d', cmap='Blues', ax=ax, cbar_kws={'label': 'Count'})\n",
    "ax.set_xlabel('Predicted', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Actual', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Isolation Forest - Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax.set_xticklabels(['Normal', 'Attack'])\n",
    "ax.set_yticklabels(['Normal', 'Attack'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/nawara/Desktop/LLM-Clustering-Paper/Anomaly_Baselines_Results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4ebe1",
   "metadata": {},
   "source": [
    "## 8. Save Results and Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b74ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save evaluation metrics\n",
    "metrics_df = pd.DataFrame([iso_results, lof_results])\n",
    "metrics_csv = \"/Users/nawara/Desktop/LLM-Clustering-Paper/baseline_metrics.csv\"\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(f\"\\n✓ Metrics saved to: {metrics_csv}\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# 2. Save test predictions with anomaly scores\n",
    "results_df = pd.DataFrame({\n",
    "    'actual_label': y_test.values,\n",
    "    'iso_forest_score': iso_test_anomaly_scores,\n",
    "    'iso_forest_pred': iso_test_binary,\n",
    "    'lof_score': lof_test_anomaly_scores,\n",
    "    'lof_pred': lof_test_binary\n",
    "})\n",
    "\n",
    "results_csv = \"/Users/nawara/Desktop/LLM-Clustering-Paper/baseline_test_predictions.csv\"\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print(f\"\\n✓ Test predictions saved to: {results_csv}\")\n",
    "print(f\"  Shape: {results_df.shape}\")\n",
    "print(f\"\\n  Sample (first 5 rows):\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a9cf9",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "BASELINE ANOMALY DETECTION MODELS\n",
    "{'='*80}\n",
    "\n",
    "✓ DATA PREPROCESSING:\n",
    "  • Train/Test Split: 70% / 30% (stratified)\n",
    "  • Categorical Encoding: LabelEncoder (fit on train only)\n",
    "  • Numeric Scaling: StandardScaler (fit on train only)\n",
    "  • No data leakage ensured\n",
    "\n",
    "✓ MODELS TRAINED:\n",
    "  1. Isolation Forest (contamination=0.1)\n",
    "  2. Local Outlier Factor (n_neighbors=20, contamination=0.1)\n",
    "\n",
    "✓ TEST SET EVALUATION:\n",
    "  \n",
    "  Isolation Forest:\n",
    "    • Accuracy:  {iso_results['Accuracy']:.4f}\n",
    "    • Precision: {iso_results['Precision']:.4f}\n",
    "    • Recall:    {iso_results['Recall']:.4f}\n",
    "    • F1-Score:  {iso_results['F1-Score']:.4f}\n",
    "    • ROC-AUC:   {iso_results['ROC-AUC']:.4f}\n",
    "  \n",
    "  Local Outlier Factor:\n",
    "    • Accuracy:  {lof_results['Accuracy']:.4f}\n",
    "    • Precision: {lof_results['Precision']:.4f}\n",
    "    • Recall:    {lof_results['Recall']:.4f}\n",
    "    • F1-Score:  {lof_results['F1-Score']:.4f}\n",
    "    • ROC-AUC:   {lof_results['ROC-AUC']:.4f}\n",
    "\n",
    "✓ OUTPUTS GENERATED:\n",
    "  1. baseline_metrics.csv - Model evaluation metrics\n",
    "  2. baseline_test_predictions.csv - Predictions + anomaly scores on test\n",
    "  3. Anomaly_Baselines_Results.png - Visualization\n",
    "\n",
    "{'='*80}\n",
    "NEXT STEPS:\n",
    "  1. Implement LLM-based clustering approach\n",
    "  2. Use same preprocessing and train/test split\n",
    "  3. Compare LLM-Clustering results against these baselines\n",
    "  4. Analyze differences in detected anomalies\n",
    "  5. Write comparison analysis for paper\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
