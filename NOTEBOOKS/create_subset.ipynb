{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63c5c0e",
   "metadata": {},
   "source": [
    "# Create Bot-IoT Dataset Subset\n",
    "\n",
    "This notebook creates a balanced subset of 300,000 rows from the merged Bot-IoT dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed4994c",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import pandas and other necessary libraries for data manipulation and file I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1370201",
   "metadata": {},
   "source": [
    "## Define Configuration Variables\n",
    "\n",
    "Set up configuration variables for the subset creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TARGET_N = 300000  # Target number of rows for the subset\n",
    "RANDOM_STATE = 42  # For reproducibility\n",
    "\n",
    "# Data directory and file paths\n",
    "DATA_DIR = \"/Users/nawara/Desktop/LLM-Clustering-Paper/Bot-IoT-Dataset\"\n",
    "MERGED_FILE = os.path.join(DATA_DIR, \"UNSW_2018_IoT_Botnet_Full_Merged.csv\")\n",
    "\n",
    "# Alternative: if using individual files instead of merged\n",
    "FILES = [\n",
    "    os.path.join(DATA_DIR, \"UNSW_2018_IoT_Botnet_Full5pc_1.csv\"),\n",
    "    os.path.join(DATA_DIR, \"UNSW_2018_IoT_Botnet_Full5pc_2.csv\"),\n",
    "    os.path.join(DATA_DIR, \"UNSW_2018_IoT_Botnet_Full5pc_3.csv\"),\n",
    "    os.path.join(DATA_DIR, \"UNSW_2018_IoT_Botnet_Full5pc_4.csv\"),\n",
    "]\n",
    "\n",
    "print(f\"Target subset size: {TARGET_N:,} rows\")\n",
    "print(f\"Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fac78a",
   "metadata": {},
   "source": [
    "## Read and Sample Data from Multiple Files\n",
    "\n",
    "Iterate through each CSV file, read it, and sample approximately equal numbers of rows from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7231cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rows to sample from each file\n",
    "per_file = TARGET_N // len(FILES)\n",
    "print(f\"Sampling approximately {per_file:,} rows from each of {len(FILES)} files\\n\")\n",
    "\n",
    "subsets = []\n",
    "for fp in FILES:\n",
    "    print(f\"Reading sample from {fp} ...\")\n",
    "    \n",
    "    # Read CSV with low_memory=False to avoid mixed type warnings\n",
    "    df = pd.read_csv(fp, low_memory=False)\n",
    "    print(f\"  Full file shape: {df.shape}\")\n",
    "    \n",
    "    # Sample rows\n",
    "    if len(df) > per_file:\n",
    "        df = df.sample(n=per_file, random_state=RANDOM_STATE)\n",
    "        print(f\"  Sampled shape: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"  File has {len(df):,} rows (less than target {per_file:,}), using all rows\")\n",
    "    \n",
    "    subsets.append(df)\n",
    "\n",
    "print(f\"\\nCollected {len(subsets)} subsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c069e",
   "metadata": {},
   "source": [
    "## Combine Subsets into Single DataFrame\n",
    "\n",
    "Use pd.concat() to combine all sampled subsets into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fe7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.concat(subsets, ignore_index=True)\n",
    "print(\"Combined subset created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f1100",
   "metadata": {},
   "source": [
    "## Inspect Subset Data\n",
    "\n",
    "Display the shape and columns of the combined subset to verify data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e16e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Subset shape:\", df_sub.shape)\n",
    "print(f\"\\nTotal rows: {len(df_sub):,}\")\n",
    "print(f\"Total columns: {len(df_sub.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_sub.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cc8e7",
   "metadata": {},
   "source": [
    "## Save Subset to CSV\n",
    "\n",
    "Save the combined subset DataFrame to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save subset\n",
    "out_csv = os.path.join(DATA_DIR, \"bot_iot_5pc_subset_300k.csv\")\n",
    "df_sub.to_csv(out_csv, index=False)\n",
    "print(f\"âœ“ Subset saved to: {out_csv}\")\n",
    "print(f\"  File size: {os.path.getsize(out_csv) / (1024**2):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
